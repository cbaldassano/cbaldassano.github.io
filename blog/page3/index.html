<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Rooting for the machines &middot; A Blog by Chris Baldassano
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/public/css/poole.css">
  <link rel="stylesheet" href="/blog/public/css/syntax.css">
  <link rel="stylesheet" href="/blog/public/css/lanyon.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">


  <!-- RSS -->
  <link rel="alternate" type="application/atom+xml" title="Blog feed" href="/atom.xml">

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-15871783-1', 'auto');
  ga('send', 'pageview');

  </script>

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@ChrisBaldassano">
  <meta name="twitter:creator" content="@ChrisBaldassano">
  
    <meta name="twitter:title" content="Home">
  
  
    <meta name="twitter:url" content="http://blog.chrisbaldassano.com//page3/">
  
  
    <meta name="twitter:description" content="A blog about real minds, artificial minds, using artificial minds to understand real minds, and using real minds to inspire artificial minds">
  


</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>A blog about real minds, artificial minds, using artificial minds to understand real minds, and using real minds to inspire artificial minds</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="http://www.chrisbaldassano.com">Main</a>
    <a class="sidebar-nav-item" href="/blog/">Blog</a>


    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/blog/archive/">Blog Archive</a>
        
      
    
      
    
      
        
      
    
      
        
      
    

    <a class="sidebar-nav-item" href="/blog/atom.xml">Atom feed</a>
    
  </nav>

  <div class="sidebar-item">
    <p>
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/blog" title="Home">Rooting for the machines</a>
            <small>A Blog by Chris Baldassano</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/2015/02/24/conchords/">
        Are you thinking what I'm thinking?
      </a>
    </h1>

    <span class="post-date">24 Feb 2015</span>

    <p><img src="/blog/public/fotc.jpg" alt="Jemaine and Bret"></p>

<p>Flight of the Conchords has been one of my favorite comedy bands for years, mixing general silliness with some insightful satire on life and relationships. They have a whole catalog of great songs (<a href="https://www.youtube.com/watch?v=BNC61-OOPdA">one of which</a> is highly relevant to the title of this blog), but one of my favorite exchanges is at 1:00 into their song &quot;We&#39;re Both in Love with a Sexy Lady&quot;:</p>

<iframe width="420" height="315" src="https://www.youtube.com/embed/OOvQ1EvMy5k?start=60" frameborder="0" allowfullscreen></iframe>

<blockquote>
<p>Bret: Are you thinking what I&#39;m thinking?</p>

<p>Jemaine: No, I&#39;m thinking what I&#39;m thinking.</p>

<p>Bret: So you&#39;re not thinking what I&#39;m thinking?</p>

<p>Jemaine: No, &#39;cause you&#39;re thinking I&#39;m thinking what you&#39;re thinking.</p>
</blockquote>

<p>Both of Jemaine&#39;s lines touch on deep concepts in cognitive science, so let&#39;s take them one at a time:</p>

<h2>I&#39;m thinking what I&#39;m thinking</h2>

<p>Jemaine&#39;s first objection is that of course he&#39;s not thinking Bret&#39;s thoughts, he&#39;s thinking his own! It is actually very unclear exactly what it means for two people to have &quot;the same&quot; thought. For systems with a standardized architecture like computers, it makes perfect sense to say that a file on my computer is the same as a file on your computer - each file consists of an ordered list of 0s and 1s, and we can just compare these two lists to see if they are the same. For neural systems, however, we can&#39;t hope to do this same kind of comparison. It seems implausible that two people could have a one-to-one correspondence between the neurons in their brains and have the same pattern of firing on these neurons. Is there a way to summarize the current state of the brain in a way that abstracts away from the architecture of a particular person&#39;s brain, and allows us to compare thoughts between people?</p>

<p>The answer is, of course, that humans invented such a system about a hundred thousand years ago, called <em>language.</em> The fact that we are able to convert our thoughts into words, and decode others&#39; words into our own thoughts, is an incredible feat. In a sense, we are all bilingual - our internal thoughts are represented by patterns of brain activity unique to our own brains, and we can translate these to and from a language that is understood by others. This sentence is some dynamic state in my brain which I have compressed into a string of characters, which your brain is then uncompressing to create a corresponding state in your brain. Language is not perfect, and we can sometimes struggle to translate our thoughts into words, but considering the complexity of the human brain (with 100 trillion connections between neurons) we can do an impressive job of copying thoughts between brains using a one-dimensional channel of text or speech.</p>

<p>There has been some early work on building computer systems which can perform this same kind of task, producing a natural language description of some complex internal representation of information. For example, <a href="http://www.nytimes.com/2014/11/18/science/researchers-announce-breakthrough-in-content-recognition-software.html?ref=science">both Stanford and Google</a> have built artificial neural network systems that can look at an image, produce some numerical vector representation of its content, and then translate that representation into a sentence that humans can understand. My labmate Andrej Karpathy has put up a <a href="http://cs.stanford.edu/people/karpathy/deepimagesent/generationdemo/">cool demo</a> of sample sentences (you can refresh to get new ones) to show how well this is currently working. It&#39;s clearly far below human performance, but describes a surprising number of images correctly.</p>

<p>Going back to human brains: though we can&#39;t expect a neuron-level correspondence between brains, might there be a more coarse similarity at the millimeter scale? Maybe the average activity of a clump of ~10,000 neurons in my brain when I think about dogs looks like the average activity in a similarly-positioned clump of neurons in your brain. There have been <a href="http://hlab.princeton.edu/Papers/Hasson_et_al_TiCS_2012_F.pdf">a great deal</a> of interesting neuroimaging experiments testing this hypothesis, and it seems that there are a number of brain regions with this property. In fact, the more in-sync a listener&#39;s brain is to the speaker&#39;s, the better they comprehend what the speaker is saying.</p>

<h2>You&#39;re thinking I&#39;m thinking what you&#39;re thinking.</h2>

<p>Jemaine&#39;s second objection is that Bret is currently thinking about a model of Jemaine&#39;s mind, and since Jemaine isn&#39;t thinking about his own mind their thoughts can&#39;t be the same. The ability to make these kind of statements, about the mental states of others, is called having a <a href="http://en.wikipedia.org/wiki/Theory_of_mind">Theory of Mind</a>. In fact, understanding Jemaine&#39;s sentence is a fourth-order theory of mind task for us as listeners: Jemaine thinks that Bret thinks that Jemaine is thinking what Bret is thinking. The fact that we can even comprehend this sentence is remarkable. No other animal (as far as we know) has the ability to build these high-order models of the thoughts of others, and humans require years of practice.</p>

<p>If you want to test how good your theory of mind skills are, take a look at one of the questions used in <a href="https://www.staff.ncl.ac.uk/daniel.nettle/liddlenettle.pdf">studies of schoolchildren</a>:</p>

<blockquote>
<p>There was a little girl called Anna who had a big problem on her mind. It was her mums birthday the very next day. Anna wanted to get her mum a birthday present, but she just didn&#39;t know what to buy. She thought and she thought. Tomorrow was nearly here! Anna remembered that her brother, Ben, had already asked mum what
mum would like most of all for her birthday. Ben was out riding his bike so Anna decided to look around his room to see if she could find what present he had got for mum. Anna went in and found a big bunch of beautiful flowers with a little card that said: &#39;Happy Birthday Mum, love from Ben.&#39; Anna thought to herself &#39;mum must want flowers for her birthday!&#39; Just as Anna was leaving the room, Ben was coming up the stairs, but he didn&#39;t see Anna leaving his room. Anna didn&#39;t want Ben to know that she had been snooping round his room, so she said to Ben: &quot;Ben, have you got mum a birthday present?&quot; Ben thought for a minute, he didn&#39;t want Anna to copy him and get mum the same present, so he said: &quot;Yes, Anna, I have. I have got mum some perfume. What have you got for her?&quot; Anna replied: &quot;Erm, nothing yet, Ben&quot; and she walked away.</p>

<p>Which is true?</p>

<p>a) Ben thinks that Anna believes that he knows that Mum wants perfume for her birthday.</p>

<p>b) Ben thinks that Anna knows that he knows that mum wants flowers for her birthday. </p>
</blockquote>

<p>11 year-olds are unable to answer this question, while most adults can. It requires tracking the knowledge states of multiple people, and understanding how each is trying to deceive the other. (In case you&#39;re still struggling, the answer is (a)).</p>

<p>There have been some efforts to incorporate basic theory of mind into AI assistants like Siri, Google Now, and Cortana, in the sense that they can keep track of basic context: if you ask about the weather and then say &quot;what about this weekend?&quot;, these systems will understand that you&#39;re still thinking about the weather and interpret your question in this context. However, I don&#39;t know of any systems that really try to build a deep understanding of the user&#39;s mental state or tackle higher-order theory of mind tasks. I predict that in the near future we&#39;ll start seeing assistants that keep track not only of what you should know, but also what you currently do and don&#39;t know, so that they can deliver information only when you need it. If my wife emails me to say that she&#39;s moved up the time of our dinner reservation, and my personal AI sees that I haven&#39;t read the email and haven&#39;t left for the restaurant, it should guess that I am mistaken about my wife&#39;s plans and interrupt what I&#39;m working on. Perhaps a more useful measure of an AI&#39;s conversational abilities than the Turing test is a theory-of-mind test: can an AI understand what we know, how we&#39;re feeling, and what we want? Feeding it some Flight of the Conchords as training data might be a good place to start.</p>


    Comments? Complaints? Contact me <a href="https://twitter.com/ChrisBaldassano">@ChrisBaldassano</a>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/2015/02/19/kaplan/">
        Jerry Kaplan&#58; The Law of Artificial Intelligence
      </a>
    </h1>

    <span class="post-date">19 Feb 2015</span>

    <p><img src="/blog/public/kaplan.jpg" alt="Kaplan"></p>

<p>Jerry Kaplan has been an interesting force in the Stanford AI community over the past couple years. He&#39;s been a major player in Silicon Valley since the 80s, was one of the early pioneers of touch-sensitive tablets and online auctions, and wrote a book about his <a href="http://www.amazon.com/Startup-A-Silicon-Valley-Adventure/dp/0140257314">1987 pen-based operating system company</a> (which was ahead of its time, unfortunately for the company). Recently, however, he seems to have a new mission of fostering a broader discussion of the history and philosophy of AI, especially on the Stanford campus. He has been giving a number of talks on these topics, and <a href="http://web.stanford.edu/class/cs22/">taught a class</a> that brought in other AI speakers. </p>

<p>His most recent talk, through the <a href="https://www.law.stanford.edu/organizations/programs-and-centers/codex-the-stanford-center-for-legal-informatics">Stanford CodeX center</a>, was partially a plug for his upcoming book, <a href="http://yalepress.yale.edu/yupbooks/book.asp?isbn=9780300213553">&quot;Humans Need Not Apply: A Guide to Wealth and Work in the Age of Artificial Intelligence&quot;</a> but focused specifically on how the legal system should handle the rise of autonomous systems. He draws a distinction between a system being &quot;conscious&quot; (which is far off for machines, and more of a philosophical question) and a system being a &quot;moral agent&quot; that is legally considered as an &quot;artificial person.&quot; Arguably corporations already fall under this definition, since they have rights (e.g. free speech) and can be charged with legal action independently from their employees (e.g. in the BP Deepwater Horizon spill).</p>

<p>Can an AI be a moral agent? Jerry argues that systems like autonomous cars are able to predict the consequences of their actions and are in control of those actions (without requiring human approval), so they meet at least a basic definition of moral agency. As has been <a href="http://www.theatlantic.com/technology/archive/2013/10/the-ethics-of-autonomous-cars/280360/">discussed by others</a>, self-driving cars will have to make decisions analogous to the philosophical &quot;trolley problem,&quot; in which every possible action results in harm to humans and value judgments must be made. Since AIs can (implicitly or explicitly) have some encoded moral system, they should bear some responsibility for their actions.</p>

<p>He proposed a few ways of actually enforcing this in practice. The simplest would be some type of licensing system, in which every AI system meeting some threshold of complexity would need to be registered with the government. If an AI is misbehaving in some way, such as a driverless taxi driving recklessly fast in hopes of a better tip, then its license would be revoked. The AI might just be destroyed, or if we think that the problem is fixable then it could be &quot;rehabilitated&quot; e.g. with new training data. There are many possible complications here (I asked him about how this would work if the AI is partially distributed in the cloud), but this general approach makes sense.</p>

<p>I&#39;m happy that we&#39;re handing over more and more control to AIs, freeing up humans from mundane tasks and probably outperforming them in many areas (though this will require some restructuring of the economy, which is a topic for another post). There are, however, some very practical problems that we need to address sooner than later - I&#39;m glad to see that technically-minded people like Jerry are diving into these issues.</p>


    Comments? Complaints? Contact me <a href="https://twitter.com/ChrisBaldassano">@ChrisBaldassano</a>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/2015/02/13/gazzaniga/">
        Michael Gazzaniga&#58; Tales from Both Sides of the Brain
      </a>
    </h1>

    <span class="post-date">13 Feb 2015</span>

    <p><img src="/blog/public/gazzaniga.jpg" alt="Gazzaniga"></p>

<p>Michael Gazzaniga&#39;s new book is <a href="http://www.amazon.com/Tales-Both-Sides-Brain-Neuroscience/dp/0062228803">Tales from Both Sides of the Brain: A Life in Neuroscience</a>, which is a memoir about his scientific study of split-brain patients. If you&#39;re unfamiliar with this work, people who have had their two brain hemispheres surgically separated (for medical reasons) show some <a href="http://www.nature.com/news/the-split-brain-a-tale-of-two-halves-1.10213">amazingly interesting behaviors</a>, which raise deep questions about consciousness and free will. Gazzaniga set out to simply write a standard popular science book about his research, but ended up publishing a much more autobiographical book that discusses the actual process of scientific discovery. As he writes in the preface:</p>

<blockquote>
<p>Most attempts at capturing the history of a scientific saga describe the seemingly ordered and logical way an idea developed... I want to present a different picture: science carried out in friendship, where discoveries are deeply embedded in the social relations of people from all walks of life. It is a wonderful way of life, spending one&#39;s years with smart people, puzzling over the mysteries and surprises of nature.</p>
</blockquote>

<p>This is a fact of scientific research that isn&#39;t often highlighted - personalities and relationships are central to the scientific community, even though it rarely looks that way to the public.</p>

<hr>

<p>One of the main takeaways from the talk for me was how young the field of neuroscience is, compared to most other hard sciences. Gazzaniga started his work in the early 1960s, when <a href="http://www.thelancet.com/journals/lancet/article/PIIS0140-6736(15)60224-0/fulltext">the term &quot;neuroscience&quot; barely even existed</a>. The fact that the founders of the field are still around should remind us that neuroscience is in its infancy, and we still know very little. Instead of being depressing, it&#39;s kind of liberating - it means that most of the big ideas and unifying theories are still out there to be discovered, and we should take everything we &quot;know&quot; so far with a grain of salt.</p>

<p>Gazzaniga said that when he started at Caltech, there were basically two rules:  </p>

<ol>
<li>Do important things: don&#39;t do an experiment just because it&#39;s a new thing to try.</li>
<li>If it&#39;s important, just do it: don&#39;t spend too much time planning and worrying about exactly the right way to test something. In my experience, it&#39;s often hard to even tell ahead of time what the hard parts are going to be, and trying things out is a must faster way to make the experiment better.</li>
</ol>

<p>Given the early state of the field, neuroscientists should take these to heart. We&#39;re still looking for the big principles of the brain and mind. Now is not the time to be polishing up the details of our models - we&#39;re still brainstorming.</p>


    Comments? Complaints? Contact me <a href="https://twitter.com/ChrisBaldassano">@ChrisBaldassano</a>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/2015/01/27/helloworld/">
        Hello World
      </a>
    </h1>

    <span class="post-date">27 Jan 2015</span>

    <p><img src="/blog/public/NG2-flare.jpg" alt="Greg Dunn Glial Flare"></p>

<div class="message">
  I visualize a time when we will be to robots what dogs are to humans. And I am rooting for the machines. -Claude Shannon, Omni Magazine (1987)
</div>

<p>I&#39;m a soon-to-be PhD who has spent the last few years at the intersection of machine learning (i.e. building systems to model complex data) and human neuroscience (i.e. trying to collect data on a complex system). I believe that both of these fields are going to have a profound impact in the coming decades, in terms of how we interact with technology, how we communicate, and how we see ourselves. In contrast to my <a href="http://www.chrisbaldassano.com">published papers</a>, in which I have to actually support my points with hard evidence, this blog is an opportunity to speculate about where we are and what&#39;s coming next.</p>


    Comments? Complaints? Contact me <a href="https://twitter.com/ChrisBaldassano">@ChrisBaldassano</a>
  </div>
  
</div>

<div class="pagination">
  
    <span class="pagination-item older">Older</span>
  
  
    
      <a class="pagination-item newer" href="/blog/page2">Newer</a>
    
  
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
