<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      The corner of your eye &middot; Rooting for the machines
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/~chrisb/blog/public/css/poole.css">
  <link rel="stylesheet" href="/~chrisb/blog/public/css/syntax.css">
  <link rel="stylesheet" href="/~chrisb/blog/public/css/lanyon.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">


  <!-- RSS -->
  <link rel="alternate" type="application/atom+xml" title="Blog feed" href="/atom.xml">

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-15871783-1', 'auto');
  ga('send', 'pageview');

  </script>

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@ChrisBaldassano">
  <meta name="twitter:creator" content="@ChrisBaldassano">
  
    <meta name="twitter:title" content="The corner of your eye">
  
  
    <meta name="twitter:url" content="http://www.princeton.edu/~chrisb/blog/2016/05/20/corner/">
  
  
    <meta name="twitter:description" content="We usually think that our eyes work like a camera, giving us a sharp, colorful picture of the world all the way from left to right and top to bottom. But we actually only get this kind of detail in a tiny window right where our eyes are pointed. If you hold your thumb out at arm&#39;s length, the width of your thumbnail is about the size of your most precise central (also called &quot;foveal&quot;) vision. Outside of that narrow spotlight, both color perception and sharpness drop off rapidly - doing high-precision tasks like reading a word is almost impossible unless you&#39;re looking right at it.

The rest of your visual field is your &quot;peripheral&quot; vision, which has only imprecise information about shape, location, and color. Out here in the corner of your eye you can&#39;t be sure of much, which is used as a constant source of fear and uncertainty in horror movies and the occult:


What's that in the mirror, or the corner of your eye?

What's that footstep following, but never passing by?

Perhaps they're all just waiting, perhaps when we're all dead,

Out they'll come a-slithering from underneath the bed.... 
Doctor Who "Listen"


What does this peripheral information get used for during visual processing? It was shown over a decade ago (by one of my current mentors, Uri Hasson) that flashing pictures in your central and peripheral vision activate different brain regions. The hypothesis is that peripheral information gets used for tasks like determining where you are, learning the layout of the room around you, and planning where to look next. But this experimental setup is pretty unrealistic. In real life we have related information coming into both central and peripheral vision at the same time, which is constantly changing and depends on where we decide to look. Can we track how visual information flows through the brain during natural viewing?

Today a new paper from me and my PhD advisors (Fei-Fei Li and Diane Beck) is out in the Journal of Vision: Pinpointing the peripheral bias in neural scene-processing networks during natural viewing (open access). I looked at fMRI data (collected and shared generously by Mike Arcaro,Sabine Kastner, Janice Chen, and Asieh Zadbood) while people were watching clips from movies and TV shows. They were free to move their eyes around and watch as you normally would, except that they were inside a huge superconducting magnet rather than on the couch (and had less popcorn). We can disentangle central and peripheral information by tracking how these streams flow out of their initial processing centers in visual cortex to regions performing more complicated functions like object recognition and navigation.

We can make maps that show where foveal information ends up (colored orange/red) and where peripheral information ends up (colored blue/purple). I&#39;m showing this on an &quot;inflated&quot; brain surface where we&#39;ve smoothed out all the wrinkles to make it easier to look at:



This roughly matches what we had previously seen with the simpler experiments: central information heads to regions for recognizing objects, letters, and faces, while peripheral information gets used by areas that process environments and big landmarks. But it also reveals some finer structure we didn&#39;t know about before. Some scene processing regions care more about the &quot;near&quot; periphery just outside the fovea and still have access to relatively high-resolution information, while others draw information from the &quot;far&quot; periphery that only provides coarse information about your current location. There are also detectable foveal vs. peripheral differences in the frontal lobe of the brain, which is pretty surprising, since this part of the brain is supposed to be performing abstract reasoning and planning that shouldn&#39;t be all that related to where the information is coming from.

This paper was my first foray into the fun world of movie-watching data, which I&#39;ve become obsessed with during my postdoc. Contrary to the what everyone&#39;s parents told them, watching TV doesn&#39;t turn off your brain - you use almost every part of your brain to understand and follow along with the story, and answering questions about videos is such a challenging problem that even the latest computer AIs are pretty terrible at it (though some of my former labmates have started making them better). We&#39;re finding that movies drive much stronger and more complex activity patterns compared to the usual paradigm of flashing individual images, and we&#39;re starting to answer questions raised by cognitive scientists in the 1970s about how complicated situations are understood and remembered - stay tuned!
">
  


  
  <meta name="twitter:image:src" content="http://www.princeton.edu/~chrisb/blog/public/periphery.png">

</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>A blog about real minds, artificial minds, using artificial minds to understand real minds, and using real minds to inspire artificial minds</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="http://www.chrisbaldassano.com">Main</a>
    <a class="sidebar-nav-item" href="/~chrisb/blog/">Blog</a>


    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/~chrisb/blog/archive/">Blog Archive</a>
        
      
    
      
    
      
        
      
    
      
        
      
    

    <a class="sidebar-nav-item" href="/~chrisb/blog/atom.xml">Atom feed</a>
    
  </nav>

  <div class="sidebar-item">
    <p>
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/~chrisb/blog" title="Home">Rooting for the machines</a>
            <small>A Blog by Chris Baldassano</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">The corner of your eye</h1>
  <span class="post-date">20 May 2016</span>
  <p>We usually think that our eyes work like a camera, giving us a sharp, colorful picture of the world all the way from left to right and top to bottom. But we actually only get this kind of detail in a tiny window right where our eyes are pointed. If you hold your thumb out at arm&#39;s length, the width of your thumbnail is about the size of your most precise central (also called &quot;foveal&quot;) vision. Outside of that narrow spotlight, both color perception and sharpness drop off rapidly - doing high-precision tasks like reading a word is almost impossible unless you&#39;re looking right at it.</p>

<p>The rest of your visual field is your &quot;peripheral&quot; vision, which has only imprecise information about shape, location, and color. Out here in the corner of your eye you can&#39;t be sure of much, which is used as a constant source of fear and uncertainty in horror movies and the occult:</p>

<div class="message">
<p>What's that in the mirror, or the corner of your eye?

<p>What's that footstep following, but never passing by?

<p>Perhaps they're all just waiting, perhaps when we're all dead,

<p>Out they'll come a-slithering from underneath the bed.... 
<p><a href="https://www.youtube.com/watch?v=vJiJZiOaJFQ">Doctor Who "Listen"</a>
</div>

<p>What does this peripheral information get used for during visual processing? It was shown over a decade ago (by one of my current mentors, <a href="http://www.weizmann.ac.il/neurobiology/labs/malach/sites/neurobiology.labs.malach/files/2002_04_Hasson_neuron.pdf">Uri Hasson</a>) that flashing pictures in your central and peripheral vision activate different brain regions. The hypothesis is that peripheral information gets used for tasks like determining where you are, learning the layout of the room around you, and planning where to look next. But this experimental setup is pretty unrealistic. In real life we have related information coming into both central and peripheral vision at the same time, which is constantly changing and depends on where we decide to look. Can we track how visual information flows through the brain during natural viewing?</p>

<p>Today a new paper from me and my PhD advisors (<a href="http://vision.stanford.edu/feifeili/">Fei-Fei Li</a> and <a href="http://www.psychology.illinois.edu/people/dmbeck">Diane Beck</a>) is out in the Journal of Vision: <a href="http://jov.arvojournals.org/article.aspx?articleid=2524115">Pinpointing the peripheral bias in neural scene-processing networks during natural viewing (open access)</a>. I looked at fMRI data (collected and shared generously by Mike Arcaro,Sabine Kastner, Janice Chen, and Asieh Zadbood) while people were watching clips from movies and TV shows. They were free to move their eyes around and watch as you normally would, except that they were inside a huge superconducting magnet rather than on the couch (and had less popcorn). We can disentangle central and peripheral information by tracking how these streams flow out of their initial processing centers in visual cortex to regions performing more complicated functions like object recognition and navigation.</p>

<p>We can make maps that show where foveal information ends up (colored orange/red) and where peripheral information ends up (colored blue/purple). I&#39;m showing this on an &quot;inflated&quot; brain surface where we&#39;ve smoothed out all the wrinkles to make it easier to look at:</p>

<p><img src="/%7Echrisb/blog/public/periphery.png" alt="Foveal and Peripheral regions"></p>

<p>This roughly matches what we had previously seen with the simpler experiments: central information heads to regions for recognizing objects, letters, and faces, while peripheral information gets used by areas that process environments and big landmarks. But it also reveals some finer structure we didn&#39;t know about before. Some scene processing regions care more about the &quot;near&quot; periphery just outside the fovea and still have access to relatively high-resolution information, while others draw information from the &quot;far&quot; periphery that only provides coarse information about your current location. There are also detectable foveal vs. peripheral differences in the frontal lobe of the brain, which is pretty surprising, since this part of the brain is supposed to be performing abstract reasoning and planning that shouldn&#39;t be all that related to where the information is coming from.</p>

<p>This paper was my first foray into the fun world of movie-watching data, which I&#39;ve become obsessed with during my postdoc. Contrary to the what everyone&#39;s parents told them, watching TV doesn&#39;t turn off your brain - you use almost every part of your brain to understand and follow along with the story, and answering questions about videos is such a challenging problem that even the latest computer AIs are pretty terrible at it (though some of <a href="http://vision.stanford.edu/publications.html">my former labmates</a> have started making them better). We&#39;re finding that movies drive much stronger and more complex activity patterns compared to the usual paradigm of flashing individual images, and we&#39;re starting to answer questions raised by cognitive scientists in the 1970s about how complicated situations are understood and remembered - stay tuned!</p>


Comments? Complaints? Contact me <a href="https://twitter.com/ChrisBaldassano">@ChrisBaldassano</a>
</div>
      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
